{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d088f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 23:29:29.459494: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 23:29:29.460274: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Recrea exactamente el mismo modelo solo desde el archivo\n",
    "modelo_payas = keras.models.load_model('modelo_payas.h5')\n",
    "\n",
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c819a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paia_generator(seed_text):\n",
    "    \n",
    "    paia = seed_text\n",
    "    next_words = 35\n",
    "\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([paia])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=23, padding='pre')\n",
    "        predict_x=modelo_payas.predict(token_list, verbose=0) \n",
    "        classes_x=np.argmax(predict_x,axis=1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == classes_x:\n",
    "                output_word = word\n",
    "                break\n",
    "        paia += \" \" + output_word\n",
    "    \n",
    "    paia_list = paia.split()\n",
    "    output = \"\"\n",
    "\n",
    "    for i in range(len(paia_list)):\n",
    "        if i==0:\n",
    "            output+=paia_list[i]\n",
    "        else:\n",
    "            if i%6 == 0:\n",
    "                output += \"\\n\" + paia_list[i]\n",
    "            else:\n",
    "                output+= \" \" + paia_list[i]\n",
    "    \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32865916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicha que no te viejo plata\n",
      "dijo que no le mejor los\n",
      "escudo brindo por el mujer vino\n",
      "un empaná me agua que la\n",
      "ramá chicha chicha por la ramá\n",
      "chicha a chicha a chicha con\n"
     ]
    }
   ],
   "source": [
    "seed = \"chicha\"\n",
    "paia = paia_generator(seed)\n",
    "print(paia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec5cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paia",
   "language": "python",
   "name": "paia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
